Introduction	

Image registration is crutical in medical diagnosis and surgery planning.  In this thesis, we focus on the problem of registering mammogram images that are taken 6 months to a year apart. Our registration algorithm closely follow the variational framework developed in [].  Unlike the previous work which performed its evaluation on ? image dataset, we apply the Large Displacement Optical Flow to medical images. Since memmogram images are different from ? dataset in the way they are captured, the registration of mommogram images poses new challenges.  An object that are physically located in the front does not completely occulude the objects behind [Figure 1]. The images are acquired months apart and taken from different viewpoints each time. Unlike many optical flow applications where the physical shape of the real object does not change, the shape of the breast change each time. Therefore it is worthwhile to carefully study how the vanillar LDOF performs on mammograms.  Specifically, we evaluate its performance in comparison to three other algorithms that are well-established in medical imaging and computer vision: the Demon’s algorithm [], Horn-Schunk algorithm [], and ---.  


In addition to different types of challeges, the medical registration often come with different requirements and constraints to satisfy, as well as the available information from domain experts that are important, if not essential, for the accurate and reliable registration. In order to satisfy the specific medical-oriented goals and leverage the knowledge from medical doctors, we extend the LDOF by adding keypoint constraints and region preservation constraints that are manually specified by domain experts (eg. radiologists).  This extension incorporates the human experiences and knowledge to the automated registration method.  Radiologists can specify an approximate region that are “preferred” to be preserved during the registration.   For instance, they can select the regions of [...?]. Unlike feature-based registrations such as [] and [],  the region of preservation needs not to be exact due to the way our energy function is devised   [Section ?].  

- why is this problem worth tackling?
The registration makes it easier for the medical doctors to compare a large datasets of images and detect the structral characteristics of different types of tumor cells which can help with a personalized treatment/chemo regimens per patient.  The registration can also serve as an important preprocessing step for learning-based approaches to higher-level problems such as cancer-recurrence predictions.

 The registration aims to preserve meaningful features/anatomical structures and does not distort them.  Also we do not want to introduce any new, false information into the registered result.  This originates from the fact that manual annotations from medical specialists regarding which general regions are important (eg. contains structural changes, abnormal cell growths, etc) can give accurate guidance to the algorithm to where to be careful when doing the registration.  One important application of this algorithm is a systematic classification of tumor shapes and its shape changes as it progresses.  


Main challenges
- 3d structure is projected to a 2D image plane
- Each time the compression, camera angles, position of the patient changes, and currently there is no available tool to manually control those variables.
- A lot of white tissues that does not contain information useful for medical diagnosis. In fact, there is a whole other field of research that tries to get rid of them out of the image so that only the meaning structure remains.
- Evaluation.  There is no ground truth registration, nor an easy way to check with alignment is better than another.  We rely on two methods.  First is to compare the location of key points.  The other is experists visual examination. 
